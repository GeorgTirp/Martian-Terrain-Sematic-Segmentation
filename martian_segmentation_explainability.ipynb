{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c5cee3",
   "metadata": {},
   "source": [
    "# Lightweight Martian Terrain Segmentation with Explainability\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "- Loading the AI4Mars dataset (Hugging Face: `hassanjbara/AI4MARS`).\n",
    "- Training a lightweight U-Net on Martian terrain labels:\n",
    "  - Classes: soil, bedrock, sand, big rock (null pixels ignored).\n",
    "- Evaluating pixel accuracy and mean IoU.\n",
    "- Visualizing predictions vs. ground truth.\n",
    "- Explainability:\n",
    "  - Grad-CAM heatmaps.\n",
    "  - Integrated Gradients saliency.\n",
    "  - \"Neural PCA\" of intermediate feature activations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c17be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import create_unet\n",
    "from data import (\n",
    "    create_ai4mars_dataloaders,\n",
    "    AI4MARS_CLASS_NAMES,\n",
    "    AI4MARS_IGNORE_INDEX,\n",
    ")\n",
    "from optimizers import create_optimizer\n",
    "from train_utils import train_one_epoch, evaluate\n",
    "from explainability import grad_cam, integrated_gradients, neural_pca\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "image_size = 256\n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "num_classes = len(AI4MARS_CLASS_NAMES)\n",
    "num_epochs = 5\n",
    "\n",
    "learning_rate = 2e-4\n",
    "weight_decay = 1e-2\n",
    "use_muon = True       # will fall back to AdamW if Muon isn't installed\n",
    "use_amp = True        # mixed precision if CUDA available\n",
    "\n",
    "out_dir = Path(\"./outputs\")\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a24959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: AI4Mars dataloaders (train/val/test)\n",
    "loaders = create_ai4mars_dataloaders(\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    num_workers=num_workers,\n",
    "    val_fraction=0.1,\n",
    "    to_rgb=False,  # AI4Mars Navcam images are essentially grayscale.\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "train_loader = loaders.train\n",
    "val_loader = loaders.val\n",
    "test_loader = loaders.test\n",
    "\n",
    "print(\n",
    "    f\"Train batches: {len(train_loader)}, \"\n",
    "    f\"Val batches: {len(val_loader)}, \"\n",
    "    f\"Test batches: {len(test_loader)}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model & optimizer\n",
    "model = create_unet(\n",
    "    in_channels=1,\n",
    "    num_classes=num_classes,\n",
    "    base_channels=32,  # adjust for lighter/heavier model\n",
    "    bilinear=True,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = create_optimizer(\n",
    "    model,\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    use_muon=use_muon,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43211728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_miou\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_miou\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "\n",
    "    train_metrics = train_one_epoch(\n",
    "        model=model,\n",
    "        dataloader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        num_classes=num_classes,\n",
    "        use_amp=use_amp,\n",
    "    )\n",
    "    val_metrics = evaluate(\n",
    "        model=model,\n",
    "        dataloader=val_loader,\n",
    "        device=device,\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "\n",
    "    history[\"train_loss\"].append(train_metrics[\"loss\"])\n",
    "    history[\"train_miou\"].append(train_metrics[\"miou\"])\n",
    "    history[\"val_loss\"].append(val_metrics[\"loss\"])\n",
    "    history[\"val_miou\"].append(val_metrics[\"miou\"])\n",
    "\n",
    "    print(\n",
    "        f\"  Train - loss: {train_metrics['loss']:.4f}, \"\n",
    "        f\"mIoU: {train_metrics['miou']:.4f}, \"\n",
    "        f\"pix acc: {train_metrics['pixel_acc']:.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Val   - loss: {val_metrics['loss']:.4f}, \"\n",
    "        f\"mIoU: {val_metrics['miou']:.4f}, \"\n",
    "        f\"pix acc: {val_metrics['pixel_acc']:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, history[\"train_loss\"], label=\"train loss\")\n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"val loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, history[\"train_miou\"], label=\"train mIoU\")\n",
    "plt.plot(epochs, history[\"val_miou\"], label=\"val mIoU\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean IoU\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation mIoU\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d7c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_metrics = evaluate(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    device=device,\n",
    "    num_classes=num_classes,\n",
    ")\n",
    "\n",
    "print(\"\\nTest metrics:\")\n",
    "print(\n",
    "    f\"  loss: {test_metrics['loss']:.4f}, \"\n",
    "    f\"mIoU: {test_metrics['miou']:.4f}, \"\n",
    "    f\"pix acc: {test_metrics['pixel_acc']:.4f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f0cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: visualize predictions vs ground truth\n",
    "def decode_mask(mask_tensor):\n",
    "    \"\"\"Convert a [H,W] mask with indices into a numpy array for plotting.\"\"\"\n",
    "    mask_np = mask_tensor.cpu().numpy()\n",
    "    return mask_np\n",
    "\n",
    "\n",
    "def show_predictions(model, dataloader, num_examples: int = 3):\n",
    "    model.eval()\n",
    "    imgs, masks = next(iter(dataloader))\n",
    "\n",
    "    imgs = imgs.to(device)\n",
    "    masks = masks.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs)\n",
    "        preds = logits.argmax(dim=1)\n",
    "\n",
    "    for i in range(min(num_examples, imgs.size(0))):\n",
    "        img = imgs[i, 0].cpu().numpy()  # [H,W]\n",
    "        gt = decode_mask(masks[i])\n",
    "        pred = decode_mask(preds[i])\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
    "        axes[0].imshow(img, cmap=\"gray\")\n",
    "        axes[0].set_title(\"Input image\")\n",
    "        axes[0].axis(\"off\")\n",
    "\n",
    "        im1 = axes[1].imshow(gt, vmin=0, vmax=num_classes, cmap=\"tab10\")\n",
    "        axes[1].set_title(\"Ground truth\")\n",
    "        axes[1].axis(\"off\")\n",
    "\n",
    "        im2 = axes[2].imshow(pred, vmin=0, vmax=num_classes, cmap=\"tab10\")\n",
    "        axes[2].set_title(\"Prediction\")\n",
    "        axes[2].axis(\"off\")\n",
    "\n",
    "        fig.colorbar(im2, ax=axes.ravel().tolist(), shrink=0.8)\n",
    "        plt.suptitle(f\"Example {i}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "show_predictions(model, test_loader, num_examples=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainability demo:\n",
    "# Grad-CAM, Integrated Gradients, Neural PCA for a single test image.\n",
    "\n",
    "model.eval()\n",
    "cam_layer = model.get_cam_layer()\n",
    "\n",
    "# Grab a single batch and pick the first sample\n",
    "imgs, masks = next(iter(test_loader))\n",
    "imgs = imgs.to(device)\n",
    "masks = masks.to(device)\n",
    "\n",
    "input_img = imgs[0:1]       # [1,1,H,W]\n",
    "target_mask = masks[0]      # [H,W]\n",
    "\n",
    "# Choose a target class to inspect visually (e.g. bedrock)\n",
    "target_class_name = \"bedrock\"\n",
    "target_class = AI4MARS_CLASS_NAMES.index(target_class_name)\n",
    "\n",
    "print(f\"Explaining class '{target_class_name}' (id={target_class})\")\n",
    "\n",
    "# Grad-CAM\n",
    "cam_map = grad_cam(\n",
    "    model=model,\n",
    "    input_tensor=input_img,\n",
    "    target_class=target_class,\n",
    "    target_layer=cam_layer,\n",
    ")  # [1,1,H,W]\n",
    "\n",
    "# Integrated Gradients\n",
    "ig_attr = integrated_gradients(\n",
    "    model=model,\n",
    "    input_tensor=input_img,\n",
    "    target_class=target_class,\n",
    "    baseline=torch.zeros_like(input_img),\n",
    "    steps=32,\n",
    ")  # [1,1,H,W]\n",
    "\n",
    "# Neural PCA on the same CAM layer features\n",
    "activations = {}\n",
    "\n",
    "def hook_activations(module, inp, out):\n",
    "    activations[\"feat\"] = out.detach().cpu()\n",
    "\n",
    "handle = cam_layer.register_forward_hook(hook_activations)\n",
    "with torch.no_grad():\n",
    "    _ = model(input_img)\n",
    "handle.remove()\n",
    "\n",
    "feat_map = activations[\"feat\"]  # [1,F,h,w]\n",
    "pcs, eigvals = neural_pca(feat_map, n_components=3)  # list of [H,W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b123b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of explainability maps\n",
    "def normalize_map(t: torch.Tensor):\n",
    "    t = t.clone().detach()\n",
    "    t_min, t_max = t.min(), t.max()\n",
    "    if (t_max - t_min) > 1e-6:\n",
    "        t = (t - t_min) / (t_max - t_min)\n",
    "    else:\n",
    "        t = torch.zeros_like(t)\n",
    "    return t\n",
    "\n",
    "\n",
    "img_np = input_img[0, 0].cpu().numpy()\n",
    "\n",
    "cam_np = cam_map[0, 0].cpu().numpy()\n",
    "ig_np = normalize_map(ig_attr[0, 0]).cpu().numpy()\n",
    "\n",
    "pc_maps = [normalize_map(pc).cpu().numpy() for pc in pcs]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(img_np, cmap=\"gray\")\n",
    "axes[0, 0].set_title(\"Input\")\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "# Grad-CAM overlay\n",
    "axes[0, 1].imshow(img_np, cmap=\"gray\")\n",
    "axes[0, 1].imshow(cam_np, cmap=\"jet\", alpha=0.5)\n",
    "axes[0, 1].set_title(f\"Grad-CAM ({target_class_name})\")\n",
    "axes[0, 1].axis(\"off\")\n",
    "\n",
    "# Integrated Gradients overlay\n",
    "axes[0, 2].imshow(img_np, cmap=\"gray\")\n",
    "axes[0, 2].imshow(ig_np, cmap=\"inferno\", alpha=0.5)\n",
    "axes[0, 2].set_title(f\"Integrated Gradients ({target_class_name})\")\n",
    "axes[0, 2].axis(\"off\")\n",
    "\n",
    "# Neural PCA components\n",
    "for i in range(3):\n",
    "    ax = axes[1, i]\n",
    "    pcm = pc_maps[i]\n",
    "    ax.imshow(pcm, cmap=\"coolwarm\")\n",
    "    ax.set_title(f\"Neural PCA PC{i+1}\\n(eig={eigvals[i].item():.2f})\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
